{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing_Set5_Set14.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fqa8Fx5nBcgb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageFilter\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import math\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "from math import log10"
      ],
      "metadata": {
        "id": "wdyRuiGpQTgT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the convolutional block\n",
        "class ConvolutionalBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, batch_norm=False, activation=None):\n",
        "        super(ConvolutionalBlock, self).__init__()\n",
        "        # check if the activation is there or not\n",
        "        if activation is not None:\n",
        "            activation = activation.lower()\n",
        "            assert activation in {'prelu', 'leakyrelu', 'tanh'}\n",
        "        # initialize an empty list, which will store the layers of the model\n",
        "        layers = list()\n",
        "        # append the first layer of Conv\n",
        "        layers.append(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                      padding=kernel_size // 2))\n",
        "        # add the BatchNorm\n",
        "        if batch_norm is True:\n",
        "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
        "        # batchNorm is followed by an activation layer\n",
        "        if activation == 'prelu':\n",
        "            layers.append(nn.PReLU())\n",
        "        elif activation == 'leakyrelu':\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        elif activation == 'tanh':\n",
        "            layers.append(nn.Tanh())\n",
        "        # create a sequential model from the list of layers.\n",
        "        self.conv_block = nn.Sequential(*layers)\n",
        "    \n",
        "    # define the forward function\n",
        "    def forward(self, input):\n",
        "        output = self.conv_block(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "# SubPixel Convolution layer\n",
        "class SubPixelConvolutionalBlock(nn.Module):\n",
        "    # pixel shuffle layer is introduced to increase the dimension at the end.\n",
        "    def __init__(self, kernel_size=3, n_channels=64, scaling_factor=2):\n",
        "        super(SubPixelConvolutionalBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=n_channels, out_channels=n_channels * (scaling_factor ** 2),\n",
        "                              kernel_size=kernel_size, padding=kernel_size // 2)\n",
        "        # r2*c*h*w --> r*c*rh*rw\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor=scaling_factor)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    # define the forward function\n",
        "    def forward(self, input):\n",
        "        output = self.conv(input)\n",
        "        output = self.pixel_shuffle(output)  \n",
        "        output = self.prelu(output) \n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# define the residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, kernel_size=3, n_channels=64):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv_block1 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,\n",
        "                                              batch_norm=True, activation='PReLu')\n",
        "\n",
        "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,\n",
        "                                              batch_norm=True, activation=None)\n",
        "\n",
        "    def forward(self, input):\n",
        "        residual = input  # (N, n_channels, w, h)\n",
        "        output = self.conv_block1(input)  # (N, n_channels, w, h)\n",
        "        output = self.conv_block2(output)  # (N, n_channels, w, h)\n",
        "        output = output + residual  # (N, n_channels, w, h)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class SRResNet(nn.Module):\n",
        "    # defining the entire structure of the SRResNet\n",
        "    def __init__(self, large_kernel_size=9, small_kernel_size=3, n_channels=64, n_blocks=16, scaling_factor=4):\n",
        "        super(SRResNet, self).__init__()\n",
        "        scaling_factor = int(scaling_factor)\n",
        "        assert scaling_factor in {2, 4, 8}\n",
        "\n",
        "        self.conv_block1 = ConvolutionalBlock(in_channels=3, out_channels=n_channels, kernel_size=large_kernel_size,\n",
        "                                              batch_norm=False, activation='PReLu')\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(kernel_size=small_kernel_size, n_channels=n_channels) for i in range(n_blocks)])\n",
        "\n",
        "        self.conv_block2 = ConvolutionalBlock(in_channels=n_channels, out_channels=n_channels,\n",
        "                                              kernel_size=small_kernel_size,\n",
        "                                              batch_norm=True, activation=None)\n",
        "\n",
        "        n_subpixel_convolution_blocks = int(math.log2(scaling_factor))\n",
        "        self.subpixel_convolutional_blocks = nn.Sequential(\n",
        "            *[SubPixelConvolutionalBlock(kernel_size=small_kernel_size, n_channels=64, scaling_factor=4) for i\n",
        "              in range(n_subpixel_convolution_blocks)])\n",
        "\n",
        "        self.conv_block3 = ConvolutionalBlock(in_channels=n_channels, out_channels=3, kernel_size=large_kernel_size,\n",
        "                                              batch_norm=False, activation='Tanh')\n",
        "\n",
        "    def forward(self, lr_imgs):\n",
        "        output = self.conv_block1(lr_imgs)  # (16, 3, 24, 24)\n",
        "        residual = output  # (16, 64, 24, 24)\n",
        "        output = self.residual_blocks(output)  # (16, 64, 24, 24)\n",
        "        output = self.conv_block2(output)  # (16, 64, 24, 24)\n",
        "        output = output + residual  # (16, 64, 24, 24)\n",
        "        output = self.subpixel_convolutional_blocks(output)  # (16, 64, 24 * 2, 24 * 2)\n",
        "        sr_imgs = self.conv_block3(output)  # (16, 3, 24 * 2, 24 * 2)\n",
        "\n",
        "        return sr_imgs\n"
      ],
      "metadata": {
        "id": "XakU1V_pQNn0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "crop_size = 600      \n",
        "scaling_factor = 2 \n",
        "\n",
        "\n",
        "large_kernel_size = 9   \n",
        "small_kernel_size = 3   \n",
        "n_channels = 64         \n",
        "n_blocks = 16           \n",
        "\n",
        "\n",
        "checkpoint = '/content/rsresnet.pth'  \n",
        "batch_size = 2    \n",
        "start_epoch = 1     \n",
        "epochs = 20      \n",
        "workers = 1        \n",
        "lr = 1e-4           \n",
        "\n",
        "pre_psnr=0\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ngpu = 1\n",
        "\n",
        "cudnn.benchmark = True \n",
        "\n",
        "\n",
        "model = torch.load(checkpoint).to(device)\n",
        "print('Loading of previous model succeded')\n",
        "    \n",
        "# defining the optimiser of the model\n",
        "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model.parameters()),lr=lr)\n",
        "# LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
        "# putting the model on the device\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5yRTtnpQEVQ",
        "outputId": "048fae30-86a8-4497-bf74-e7b50fe81390"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading of previous model succeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiCch0J9PrzU",
        "outputId": "57cb2553-4242-4781-bf4b-ebb8d7521f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRResNet(\n",
            "  (conv_block1): ConvolutionalBlock(\n",
            "    (conv_block): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "      (1): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (residual_blocks): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (6): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (7): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (8): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (9): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (10): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (11): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (12): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (13): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (14): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (15): ResidualBlock(\n",
            "      (conv_block1): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (conv_block2): ConvolutionalBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (conv_block2): ConvolutionalBlock(\n",
            "    (conv_block): Sequential(\n",
            "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (subpixel_convolutional_blocks): Sequential(\n",
            "    (0): SubPixelConvolutionalBlock(\n",
            "      (conv): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
            "      (prelu): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (conv_block3): ConvolutionalBlock(\n",
            "    (conv_block): Sequential(\n",
            "      (0): Conv2d(64, 3, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SRDataset(Dataset):\n",
        "    def __init__(self, data_path, crop_size, scaling_factor):\n",
        "        self.data_path=data_path\n",
        "        self.crop_size = int(crop_size)\n",
        "        self.scaling_factor = int(scaling_factor)\n",
        "        self.images_path=[]\n",
        "\n",
        "        \n",
        "        for name in os.listdir(self.data_path):\n",
        "            self.images_path.append(os.path.join(self.data_path,name))\n",
        "\n",
        "        # transformation common for both\n",
        "        self.pre_trans=transforms.Compose([\n",
        "                                transforms.CenterCrop(self.crop_size),\n",
        "                                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                                transforms.RandomVerticalFlip(p=0.5)\n",
        "                                ])\n",
        "        \n",
        "        # transformation only for the input class [lr images]\n",
        "        self.input_transform = transforms.Compose([\n",
        "                                transforms.Resize(self.crop_size//self.scaling_factor),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "                                ])\n",
        "        \n",
        "        # transformation only for the target class [hr images]\n",
        "        self.target_transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],std=[0.5]),\n",
        "                                ])\n",
        "\n",
        "    # get an element based on index value\n",
        "    # get the lr image and the hr image\n",
        "    def __getitem__(self, i):\n",
        "        img = Image.open(self.images_path[i], mode='r')\n",
        "        img = img.convert('RGB')\n",
        "        img=self.pre_trans(img)\n",
        "\n",
        "        lr_img = self.input_transform(img)\n",
        "        hr_img = self.target_transform(img.copy())\n",
        "        \n",
        "        return lr_img, hr_img\n",
        "\n",
        "    # get the length of the input image\n",
        "    def __len__(self):\n",
        "        return len(self.images_path)"
      ],
      "metadata": {
        "id": "wW3dyPFkaYXm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Set5.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVc1vXeUbzw4",
        "outputId": "42c9eb02-5b4d-40d4-9b78-3839d04d3374"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Set5.zip\n",
            "  inflating: Set5/baby.png           \n",
            "  inflating: Set5/bird.png           \n",
            "  inflating: Set5/butterfly.png      \n",
            "  inflating: Set5/head.png           \n",
            "  inflating: Set5/woman.png          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZeFzfl6F1u39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/Set5\""
      ],
      "metadata": {
        "id": "Wmwnv1e0dP3W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "dataset = SRDataset(path, crop_size, scaling_factor)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    pin_memory=True)\n",
        "\n",
        "\n",
        "model.eval()  \n",
        "test_loss=0\n",
        "all_psnr = 0\n",
        "n_iter = len(loader)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i, (lr_imgs, hr_imgs) in enumerate(loader):\n",
        "    with torch.no_grad():\n",
        "        lr_imgs = lr_imgs.to(device)\n",
        "        hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "        sr_imgs = model(lr_imgs)\n",
        "        \n",
        "\n",
        "        loss = criterion(sr_imgs, hr_imgs)\n",
        "\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "\n",
        "        all_psnr+=psnr\n",
        "        test_loss+=loss.item()\n",
        "    \n",
        "\n",
        "epoch_loss_test=test_loss/n_iter\n",
        "epoch_psnr=all_psnr / n_iter\n",
        "\n",
        "\n",
        "print(f\"Average PSNR Set 5 dataset, Model with Batchnorm in Residual blocks: {epoch_psnr} dB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz16fSuwcD_g",
        "outputId": "991bce3b-345a-4d02-bea0-6b0375bf39a9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR Set 5 dataset, Model with Batchnorm in Residual blocks: 30.776351084623087 dB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Set14.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6REaslZbjfV",
        "outputId": "c18328f9-1f2e-40fa-e2fa-7fe731e1d27f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Set14.zip\n",
            "  inflating: Set14/baboon.png        \n",
            "  inflating: Set14/barbara.png       \n",
            "  inflating: Set14/bridge.png        \n",
            "  inflating: Set14/coastguard.png    \n",
            "  inflating: Set14/comic.png         \n",
            "  inflating: Set14/face.png          \n",
            "  inflating: Set14/flowers.png       \n",
            "  inflating: Set14/foreman.png       \n",
            "  inflating: Set14/lenna.png         \n",
            "  inflating: Set14/man.png           \n",
            "  inflating: Set14/monarch.png       \n",
            "  inflating: Set14/pepper.png        \n",
            "  inflating: Set14/ppt3.png          \n",
            "  inflating: Set14/zebra.png         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set14path = \"/content/Set14\"\n",
        "dataset = SRDataset(set14path, crop_size, scaling_factor)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    pin_memory=True)\n",
        "\n",
        "\n",
        "model.eval()  \n",
        "test_loss=0\n",
        "all_psnr = 0\n",
        "n_iter = len(loader)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i, (lr_imgs, hr_imgs) in enumerate(loader):\n",
        "    with torch.no_grad():\n",
        "        lr_imgs = lr_imgs.to(device)\n",
        "        hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "        sr_imgs = model(lr_imgs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss = criterion(sr_imgs, hr_imgs)\n",
        "\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "\n",
        "        all_psnr+=psnr\n",
        "        test_loss+=loss.item()\n",
        "    \n",
        "\n",
        "epoch_loss_test=test_loss/n_iter\n",
        "epoch_psnr=all_psnr / n_iter\n",
        "\n",
        "\n",
        "print(f\"Average PSNR Set 14 dataset, Model with Batchnorm in Residual blocks: {epoch_psnr} dB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH6ZemAHe8lu",
        "outputId": "6fa79145-dbe4-48b2-8f5e-32f7ad9b6ace"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR Set 14 dataset, Model with Batchnorm in Residual blocks: 24.702948793059193 dB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model without Batchnorm"
      ],
      "metadata": {
        "id": "CyC3jWOVvqfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_wo_bn_chkpt = \"/content/resnet_default_False.pth\"\n",
        "\n",
        "\n",
        "crop_size = 600      \n",
        "scaling_factor = 2 \n",
        "\n",
        "\n",
        "large_kernel_size = 9   \n",
        "small_kernel_size = 3   \n",
        "n_channels = 64         \n",
        "n_blocks = 16           \n",
        "\n",
        "\n",
        "  \n",
        "batch_size = 2    \n",
        "start_epoch = 1     \n",
        "epochs = 20      \n",
        "workers = 1        \n",
        "lr = 1e-4           \n",
        "\n",
        "pre_psnr=0\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "ngpu = 1\n",
        "\n",
        "cudnn.benchmark = True \n",
        "\n",
        "\n",
        "model_wo = torch.load(model_wo_bn_chkpt).to(device)\n",
        "print('Loading of previous model succeded')\n",
        "    \n",
        "# defining the optimiser of the model\n",
        "optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, model_wo.parameters()),lr=lr)\n",
        "# LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
        "# putting the model on the device\n",
        "model_wo = model_wo.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74laNzpCvZvc",
        "outputId": "39d1a97d-815a-45b3-d171-e64b0fe948f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading of previous model succeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "dataset = SRDataset(path, crop_size, scaling_factor)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    pin_memory=True)\n",
        "\n",
        "\n",
        "model_wo.eval()  \n",
        "test_loss=0\n",
        "all_psnr = 0\n",
        "n_iter = len(loader)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i, (lr_imgs, hr_imgs) in enumerate(loader):\n",
        "    with torch.no_grad():\n",
        "        lr_imgs = lr_imgs.to(device)\n",
        "        hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "        sr_imgs = model_wo(lr_imgs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss = criterion(sr_imgs, hr_imgs)\n",
        "\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "\n",
        "        all_psnr+=psnr\n",
        "        test_loss+=loss.item()\n",
        "    \n",
        "\n",
        "epoch_loss_test=test_loss/n_iter\n",
        "epoch_psnr=all_psnr / n_iter\n",
        "\n",
        "\n",
        "print(f\"Average PSNR Set 5 dataset, Model with Batchnorm in Residual blocks: {epoch_psnr} dB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggBlXG7Rwb5N",
        "outputId": "30ee4456-7a3a-47c3-ea4b-452a5de4b685"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR Set 5 dataset, Model with Batchnorm in Residual blocks: 30.685715845418386 dB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "set14path = \"/content/Set14\"\n",
        "dataset = SRDataset(set14path, crop_size, scaling_factor)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    pin_memory=True)\n",
        "\n",
        "\n",
        "model_wo.eval()  \n",
        "test_loss=0\n",
        "all_psnr = 0\n",
        "n_iter = len(loader)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for i, (lr_imgs, hr_imgs) in enumerate(loader):\n",
        "    with torch.no_grad():\n",
        "        lr_imgs = lr_imgs.to(device)\n",
        "        hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "        sr_imgs = model_wo(lr_imgs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss = criterion(sr_imgs, hr_imgs)\n",
        "\n",
        "        psnr = 10 * log10(1 / loss.item())\n",
        "\n",
        "        all_psnr+=psnr\n",
        "        test_loss+=loss.item()\n",
        "    \n",
        "\n",
        "epoch_loss_test=test_loss/n_iter\n",
        "epoch_psnr=all_psnr / n_iter\n",
        "\n",
        "\n",
        "print(f\"Average PSNR Set 14 dataset, Model with Batchnorm in Residual blocks: {epoch_psnr} dB.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUrqBB_zwu4X",
        "outputId": "68fea2be-8f5c-4676-b95f-981794266ac0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR Set 14 dataset, Model with Batchnorm in Residual blocks: 25.981879256546158 dB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U1pSKUtQxDU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}